{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare of the library usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 21:56:04.351016: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-06 21:56:04.401405: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-06 21:56:04.648669: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-06 21:56:04.648756: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-06 21:56:04.649784: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-06 21:56:04.765211: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-06 21:56:04.767607: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-06 21:56:14.185429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image, ImageEnhance\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow GPU support enabled: True\n",
      "GPU device available: []\n",
      "No GPU devices available.\n",
      "CUDA version: 11.8\n",
      "cuDNN version: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 21:56:25.306855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-06 21:56:25.492836: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Check if TensorFlow is built with GPU support\n",
    "print(\"TensorFlow GPU support enabled:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Check if a GPU device is available\n",
    "print(\"GPU device available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Print the list of available GPUs\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for device in physical_devices:\n",
    "        print(\"GPU Device:\", device)\n",
    "else:\n",
    "    print(\"No GPU devices available.\")\n",
    "\n",
    "# Get details of the CUDA and cuDNN versions (if available)\n",
    "cuda_version = tf.sysconfig.get_build_info()[\"cuda_version\"]\n",
    "cudnn_version = tf.sysconfig.get_build_info()[\"cudnn_version\"]\n",
    "print(\"CUDA version:\", cuda_version)\n",
    "print(\"cuDNN version:\", cudnn_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to your dataset directories\n",
    "train_dir = \"/home/tairo/UVASTRAL/dev/DataSet/Train\"\n",
    "validation_dir = \"/home/tairo/UVASTRAL/dev/DataSet/Validation\"\n",
    "test_dir = \"/home/tairo/UVASTRAL/dev/DataSet/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to count images in a folder\n",
    "#Named: count_images\n",
    "def count_images(directory): #checking for the path to the main directory \n",
    "    total_images = 0 #initialize a variables\n",
    "    for class_folder in os.listdir(directory): \n",
    "        class_path = os.path.join(directory, class_folder)\n",
    "        if os.path.isdir(class_path):\n",
    "            total_images += len([img for img in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, img))])\n",
    "    return total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting images before preprocessing...\n",
      "Train: 0 images\n",
      "Validation: 0 images\n",
      "Test: 0 images\n"
     ]
    }
   ],
   "source": [
    "# Count and display images before preprocessing\n",
    "print(\"Counting images before preprocessing...\")\n",
    "total_train_before = count_images(train_dir)\n",
    "total_validation_before = count_images(validation_dir)\n",
    "total_test_before = count_images(test_dir)\n",
    "\n",
    "print(f\"Train: {total_train_before} images\")\n",
    "print(f\"Validation: {total_validation_before} images\")\n",
    "print(f\"Test: {total_test_before} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resize all images and perform augmentation\n",
    "def preprocess_and_augment(directory):\n",
    "    for class_folder in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_folder)\n",
    "        \n",
    "        if not os.path.isdir(class_path):\n",
    "            continue  # Skip non-directory files\n",
    "        \n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            \n",
    "            if not os.path.isfile(image_path):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Open image and resize to 224x224\n",
    "                img = Image.open(image_path).convert('RGB')\n",
    "                img = img.resize((224, 224))  # All images resized to 224x224\n",
    "                \n",
    "                # Overwrite the original image with the resized version\n",
    "                img.save(image_path)\n",
    "                \n",
    "                # Get base name and extension\n",
    "                base_name, ext = os.path.splitext(image_name)\n",
    "                \n",
    "                # Flipping horizontally\n",
    "                flipped_img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "                flipped_name = f\"{base_name}_flipped{ext}\"\n",
    "                flipped_path = os.path.join(class_path, flipped_name)\n",
    "                flipped_img.save(flipped_path)\n",
    "                \n",
    "                # Rotating (30 degrees clockwise)\n",
    "                rotated_img = img.rotate(30, expand=True)\n",
    "                rotated_name = f\"{base_name}_rotated{ext}\"\n",
    "                rotated_path = os.path.join(class_path, rotated_name)\n",
    "                rotated_img.save(rotated_path)\n",
    "                \n",
    "                # Brightness enhancement\n",
    "                enhancer = ImageEnhance.Brightness(img)\n",
    "                bright_img = enhancer.enhance(1.5)  # Increase brightness by 50%\n",
    "                bright_name = f\"{base_name}_bright{ext}\"\n",
    "                bright_path = os.path.join(class_path, bright_name)\n",
    "                bright_img.save(bright_path)\n",
    "                \n",
    "                # Random color enhancement\n",
    "                color_enhancer = ImageEnhance.Color(img)\n",
    "                color_img = color_enhancer.enhance(1.2)  # Slightly increase color\n",
    "                color_name = f\"{base_name}_color{ext}\"\n",
    "                color_path = os.path.join(class_path, color_name)\n",
    "                color_img.save(color_path)\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing and augmenting Train dataset...\n",
      "Processing and augmenting Validation dataset...\n",
      "Processing and augmenting Test dataset...\n",
      "\n",
      "Counting images after preprocessing and augmentation...\n",
      "Train: 0 images\n",
      "Validation: 0 images\n",
      "Test: 0 images\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and augment Train, Validation, and Test datasets\n",
    "print(\"\\nProcessing and augmenting Train dataset...\")\n",
    "preprocess_and_augment(train_dir)\n",
    "\n",
    "print(\"Processing and augmenting Validation dataset...\")\n",
    "preprocess_and_augment(validation_dir)\n",
    "\n",
    "print(\"Processing and augmenting Test dataset...\")\n",
    "preprocess_and_augment(test_dir)\n",
    "\n",
    "# Count and display images after augmentation\n",
    "print(\"\\nCounting images after preprocessing and augmentation...\")\n",
    "total_train_after = count_images(train_dir)\n",
    "total_validation_after = count_images(validation_dir)\n",
    "total_test_after = count_images(test_dir)\n",
    "\n",
    "print(f\"Train: {total_train_after} images\")\n",
    "print(f\"Validation: {total_validation_after} images\")\n",
    "print(f\"Test: {total_test_after} images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv",
   "language": "python",
   "name": "uv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
